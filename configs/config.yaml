# Dataset configuration
# Choose one of the following dataset configurations:

# 1. HuggingFace Datasets
# Uncomment and modify the configuration you want to use
dataset:
  # ImageNet configuration
  type: "huggingface"  # Specify to use HuggingFace dataset loader
  name: "imagenet-1k"
  batch_size: 32
  num_workers: 4
  image_size: 224
  image_key: "image"    # Key for accessing images in the dataset
  label_key: "label"    # Key for accessing labels in the dataset
  mean: [0.485, 0.456, 0.406]  # ImageNet means
  std: [0.229, 0.224, 0.225]   # ImageNet stds

# Alternative HuggingFace dataset configurations:
#
# CIFAR-10:
# dataset:
#   type: "huggingface"
#   name: "cifar10"
#   batch_size: 128
#   num_workers: 4
#   image_size: 224
#   image_key: "img"
#   label_key: "label"
#   mean: [0.4914, 0.4822, 0.4465]
#   std: [0.2023, 0.1994, 0.2010]
#
# MNIST:
# dataset:
#   type: "huggingface"
#   name: "mnist"
#   batch_size: 64
#   num_workers: 4
#   image_size: 224
#   image_key: "image"
#   label_key: "label"
#   mean: [0.1307]
#   std: [0.3081]
#
# Custom Dataset:
# dataset:
#   type: "huggingface"
#   name: "your/dataset"
#   batch_size: 32
#   num_workers: 4
#   image_size: 224
#   image_key: "image"
#   label_key: "label"
#   mean: [0.5, 0.5, 0.5]
#   std: [0.5, 0.5, 0.5]

# 2. Local DermMNIST (original configuration)
# dataset:
#   type: "dermmnist"
#   data_dir: "data/dermmnist"
#   batch_size: 32
#   num_workers: 4
#   image_size: 224

# Model configurations
models:
  - name: "google/vit-base-patch16-224"
    num_classes: 1000  # ImageNet has 1000 classes
    learning_rate: 0.0001
    weight_decay: 0.01

# Training configuration
training:
  max_epochs: 10
  accelerator: "gpu"
  devices: 1
  strategy: "auto"
  precision: 32  # Use 16 for faster training if your GPU supports it

# Logging configuration
logging:
  project_name: "vision-benchmark"
  save_dir: "logs"
  log_every_n_steps: 50
