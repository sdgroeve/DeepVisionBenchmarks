# Dataset configuration
# Choose one of the following dataset configurations:

# 1. HuggingFace Datasets
# Uncomment and modify the configuration you want to use
dataset:
  # MNIST configuration
  type: "huggingface"
  name: "mnist"
  batch_size: 32
  num_workers: 4
  image_key: "image"
  label_key: "label"
  mean: [0.1307]  # MNIST mean
  std: [0.3081]   # MNIST std
  num_channels: 1  # MNIST is grayscale

# Alternative HuggingFace dataset configurations:
#
# CIFAR-10:
# dataset:
#   type: "huggingface"
#   name: "cifar10"
#   batch_size: 128
#   num_workers: 4
#   image_key: "img"
#   label_key: "label"
#   mean: [0.4914, 0.4822, 0.4465]
#   std: [0.2023, 0.1994, 0.2010]
#   num_channels: 3
#
# ImageNet:
# dataset:
#   type: "huggingface"
#   name: "imagenet-1k"
#   batch_size: 32
#   num_workers: 4
#   image_key: "image"
#   label_key: "label"
#   mean: [0.485, 0.456, 0.406]
#   std: [0.229, 0.224, 0.225]
#   num_channels: 3

# Model configurations
models:
  - name: "google/vit-base-patch16-224"
    num_classes: 10  # MNIST has 10 classes
    learning_rate: 0.0001
    weight_decay: 0.01
    input_size: 224  # Required input size for the model

# Training configuration
training:
  max_epochs: 10
  accelerator: "gpu"
  devices: 1
  strategy: "auto"
  precision: 32  # Use 16 for faster training if your GPU supports it

# Logging configuration
logging:
  project_name: "vision-benchmark"
  save_dir: "logs"
  log_every_n_steps: 50
